{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# magic! (don't worry about this)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let us import some useful things\n",
    "from lib import *\n",
    "from classifiers import *\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data same as before\n",
    "microarray_file_name = '../data/leukemia_ALL_AML_matrix.txt'\n",
    "labels_file_name = '../data/leukemia_ALL_AML_labels.txt'\n",
    "data_store = DataSet(microarray_file_name, labels_file_name)\n",
    "\n",
    "# we will use all our samples!\n",
    "full_data_set = np.array(data_store.get_train_set() + data_store.get_test_set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# n-Fold Cross-Validation  #\n",
    "############################\n",
    "\n",
    "# let's partition the data into n splits \n",
    "from sklearn import cross_validation\n",
    "\n",
    "# feel free to adjust this parameter\n",
    "n = 3\n",
    "max_knn_k = (n-1)*len(full_data_set)/n\n",
    "\n",
    "# n_folds provides the indices for n partitions\n",
    "# From docs: Split dataset into n consecutive folds. Each fold is then used as a validation set \n",
    "# once while the n - 1 remaining folds form the training set.\n",
    "n_folds = cross_validation.KFold(len(full_data_set), n, shuffle=True)\n",
    "\n",
    "# TODO: play around with the n_folds object to figure out what it really stores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# Evaluation Metrics       #\n",
    "############################\n",
    "\n",
    "# this is our function to evaluate the accuracy of the classifier\n",
    "def get_accuracy(classified_samples):\n",
    "    correct = [1 if guess == sample.get_label() else 0 for sample, guess in classified_samples]\n",
    "    total = len(correct)\n",
    "    acc = (correct.count(1) * 100.0) / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of informative genes:  1713\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# Feature Selection #\n",
    "####################\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.special import stdtr\n",
    "\n",
    "# enable the t-test gene selection for binary datasets\n",
    "ENABLE_SELECTION = True\n",
    "\n",
    "samples_by_label = {}\n",
    "if ENABLE_SELECTION:\n",
    "    for sample in full_data_set:\n",
    "        if(sample.get_label() not in samples_by_label):\n",
    "            samples_by_label[sample.get_label()] = []\n",
    "        samples_by_label[sample.get_label()].append(sample.get_gene_profile())\n",
    "        \n",
    "    # let's select our most useful genes based on the Welch's t-test!\n",
    "    init_number_of_genes = len(full_data_set[0].get_gene_profile())\n",
    "    selected_genes = []\n",
    "    for gene_id in range(init_number_of_genes):\n",
    "        profiles_by_label = [] \n",
    "        for label in samples_by_label:\n",
    "            profiles_by_label.append([profile[gene_id] for profile in samples_by_label[label]])\n",
    "\n",
    "        # we assume there are only two labels here\n",
    "        t, p_value = ttest_ind(profiles_by_label[0], profiles_by_label[1], equal_var=False)\n",
    "        \n",
    "        if(p_value < 0.05):\n",
    "            selected_genes.append(gene_id)\n",
    "\n",
    "    print 'Number of informative genes: ' , len(selected_genes)\n",
    "\n",
    "    # now let's update our dataset to ignore the genes that are not informative\n",
    "    filtered_samples = []\n",
    "    for sample in full_data_set:\n",
    "        new_sample = Sample(sample.get_label(), [sample.get_gene_profile()[i] for i in range(init_number_of_genes) if i in selected_genes])\n",
    "        filtered_samples.append(new_sample)\n",
    "\n",
    "    full_data_set = np.array(filtered_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1  Average accuracy: 88.89%\n",
      "k =  2  Average accuracy: 93.06%\n",
      "k =  3  Average accuracy: 94.44%\n",
      "k =  4  Average accuracy: 95.83%\n",
      "k =  5  Average accuracy: 97.22%\n",
      "k =  6  Average accuracy: 97.22%\n",
      "k =  7  Average accuracy: 97.22%\n",
      "k =  8  Average accuracy: 97.22%\n",
      "k =  9  Average accuracy: 97.22%\n",
      "k =  10  Average accuracy: 95.83%\n",
      "k =  11  Average accuracy: 95.83%\n",
      "k =  12  Average accuracy: 94.44%\n",
      "k =  13  Average accuracy: 94.44%\n",
      "k =  14  Average accuracy: 91.67%\n",
      "k =  15  Average accuracy: 91.67%\n",
      "k =  16  Average accuracy: 87.50%\n",
      "k =  17  Average accuracy: 87.50%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-b51ca9913913>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mclassified_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassified_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mavg_acc_for_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/viq/projects/sailors-compbio/code/classifiers.pyc\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, test_samples, k, distance_metric)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlabelled_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mlabelled_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabelled_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/viq/projects/sailors-compbio/code/classifiers.pyc\u001b[0m in \u001b[0;36mclassify_sample\u001b[0;34m(self, test_sample, k, distance_metric)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# compute the distance between the gene expression profiles of the two samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gene_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gene_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/viq/projects/sailors-compbio/code/classifiers.pyc\u001b[0m in \u001b[0;36meuclidean_distance\u001b[0;34m(sample_profile1, sample_profile2)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_profile1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_profile1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msample_profile2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################\n",
    "# kNN Evaluation #\n",
    "##################\n",
    "\n",
    "# feel free to change these bounds!\n",
    "k_start = 1\n",
    "k_end = 21\n",
    "\n",
    "if k_end >= max_knn_k:\n",
    "    print 'WARNING: your kNN bound on k exceeds the number of samples in your training set!'\n",
    "\n",
    "knn = KNearestNeighbors()\n",
    "\n",
    "# we are going to average the accuracy we get for each k across all the folds!\n",
    "avg_acc_for_k = {}\n",
    "for k in range(k_start, k_end):   \n",
    "    avg_acc_for_k[k] = 0\n",
    "    for train_partition, test_partition in n_folds:\n",
    "        # TODO: can you figure out how the length of the train_set and test_set are affected by n?\n",
    "        train_set = full_data_set[train_partition]\n",
    "        test_set = full_data_set[test_partition]\n",
    "    \n",
    "        knn.train(train_set) \n",
    "        classified_samples = knn.classify(test_set, k, euclidean_distance)\n",
    "        acc = get_accuracy(classified_samples)\n",
    "        avg_acc_for_k[k] += acc\n",
    "    \n",
    "    avg_acc_for_k[k] /= len(n_folds)\n",
    "    print 'k = ', k, ' Average accuracy: %.2f%%' % avg_acc_for_k[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average accuracy: 87.28%\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# Decision Tree Evaluation #\n",
    "############################\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "# This train function is *almost* the same as the train method that \n",
    "# your knn classifier. The difference is that this is a function that\n",
    "# takes as one of the parameters the decision tree, so it will be called\n",
    "# like: train(decision_tree, train_samples)\n",
    "def train(decision_tree, train_samples):\n",
    "    feature_array = [sample.get_gene_profile() for sample in train_samples]\n",
    "    labels = [sample.get_label() for sample in train_samples]\n",
    "    decision_tree.fit(feature_array, labels)\n",
    "\n",
    "def classify(decision_tree, test_samples):\n",
    "    labelled_samples = []\n",
    "    feature_array = [sample.get_gene_profile() for sample in test_samples]\n",
    "    results = decision_tree.predict(feature_array)\n",
    "    labelled_samples = [(test_samples[i], results[i]) for i in range(len(test_samples))]\n",
    "    return labelled_samples\n",
    "\n",
    "# Here, you can set criterion = \"entropy\" or \"gini\", which will determine\n",
    "# what equation the decision tree will use to measure the quality of a split\n",
    "#\n",
    "# You can set max_features=None, \"sqrt\", or \"log2\", which will determine how many\n",
    "# features the decision tree will use. Setting it to None will use all the features,\n",
    "# sqrt will use sqrt(number of features) and log2 will use log2(number of features)\n",
    "#\n",
    "# Play around! What settings are best? Do they change for the different data sets?\n",
    "\n",
    "n_rounds = 50\n",
    "\n",
    "avg_acc = 0\n",
    "for i in range(n_rounds):\n",
    "    for train_partition, test_partition in n_folds:\n",
    "        train_set = full_data_set[train_partition]\n",
    "        test_set = full_data_set[test_partition]\n",
    "\n",
    "        decision_tree = tree.DecisionTreeClassifier(criterion=\"gini\", max_features=None)\n",
    "        train(decision_tree, train_set)\n",
    "        classified_samples = classify(decision_tree, test_set)\n",
    "        # let's evaluate how well the classifier worked\n",
    "        acc = get_accuracy(classified_samples)\n",
    "        avg_acc += acc\n",
    "    \n",
    "avg_acc /= n_rounds*len(n_folds)\n",
    "print ' Average accuracy: %.2f%%' % avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
